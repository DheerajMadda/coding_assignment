{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a00ec0",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1407051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d890f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4f873",
   "metadata": {},
   "source": [
    "## 2. Dataset - Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edcd20b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Images: 69863\n",
      "Total Val Images: 10000\n",
      "Total Train Labels: 69863\n",
      "Total Val Labels: 10000\n"
     ]
    }
   ],
   "source": [
    "images_dir =  os.path.join(\"data\", \"bdd100k_images_100k\", \"bdd100k\", \"images\", \"100k\")\n",
    "labels_dir = os.path.join(\"data\", \"bdd100k_labels_csv\",)\n",
    "\n",
    "train_images = os.listdir(os.path.join(images_dir, \"train\"))\n",
    "val_images = os.listdir(os.path.join(images_dir, \"val\"))\n",
    "\n",
    "train_label_df = pd.read_csv(os.path.join(labels_dir, \"train_labels.csv\"))\n",
    "val_label_df = pd.read_csv(os.path.join(labels_dir, \"val_labels.csv\"))\n",
    "\n",
    "train_labels = train_label_df[\"file_name\"].unique().tolist()\n",
    "val_labels = val_label_df[\"file_name\"].unique().tolist()\n",
    "\n",
    "train_files = set(train_images).intersection(set(train_labels))\n",
    "val_files = set(val_images).intersection(set(val_labels))\n",
    "\n",
    "print(f\"Total Train Images: {len(train_files)}\")\n",
    "print(f\"Total Val Images: {len(val_files)}\")\n",
    "\n",
    "print(f\"Total Train Labels: {len(train_labels)}\")\n",
    "print(f\"Total Val Labels: {len(val_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9109e",
   "metadata": {},
   "source": [
    "## 3. Helper class/ functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b3bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels_txt(label_df: pd.DataFrame, attributes: List, file_names: List, save_dir: str):\n",
    "\n",
    "    for attribute in attributes:\n",
    "        os.makedirs(os.path.join(save_dir, attribute), exist_ok=True)\n",
    "        \n",
    "    if isinstance(label_df[\"bbox\"].iloc[0], str):\n",
    "        label_df = label_df.copy()\n",
    "        label_df[\"bbox\"] = label_df[\"bbox\"].apply(eval)\n",
    "        \n",
    "    for file_name in tqdm(file_names, total=len(file_names)):\n",
    "        \n",
    "        scene_df = label_df.query(\"file_name == @file_name\")\n",
    "        if scene_df.empty:\n",
    "            continue\n",
    "        \n",
    "        for attribute in attributes:\n",
    "\n",
    "            if attribute == \"all\":\n",
    "                target_df = scene_df\n",
    "            elif attribute in [\"occluded\", \"truncated\", \"small\", \"medium\", \"large\"]:\n",
    "                target_df = scene_df.query(f\"{attribute} == True and uncertain == False\")\n",
    "            elif attribute == \"uncertain\":\n",
    "                target_df = scene_df.query(f\"{attribute} == True\")\n",
    "\n",
    "            if target_df.empty:\n",
    "                continue\n",
    "\n",
    "            save_file = os.path.join(save_dir, attribute, file_name.replace(\".jpg\", \".txt\"))\n",
    "            with open(save_file, \"w\") as f:\n",
    "                for label, bbox in zip(target_df[\"label\"], target_df[\"bbox\"]):\n",
    "                    f.write(f\"{label} \" + \" \".join(map(str, bbox)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42231d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(loader: DataLoader):\n",
    "    channels_sum, channels_sqrd_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for image in loader:\n",
    "        channels_sum += torch.mean(image, dim=[0, 2, 3])\n",
    "        channels_sqrd_sum += torch.mean(image ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_sqrd_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "class MeanStdDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform):\n",
    "        \n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "    \n",
    "    def read_image(self, path):\n",
    "        return cv2.cvtColor(\n",
    "            cv2.imread(path, cv2.IMREAD_COLOR), \n",
    "            cv2.COLOR_BGR2RGB\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Load image\n",
    "        image = self.read_image(self.image_paths[idx])\n",
    "\n",
    "        # transform image\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c09b3",
   "metadata": {},
   "source": [
    "## 4. Compute Dataset Mean and Std (on Train data only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir_train = os.path.join(images_dir, \"train\")\n",
    "image_paths = [os.path.join(images_dir_train, path) for path in train_files]\n",
    "\n",
    "IMAGE_HEIGHT = 480\n",
    "IMAGE_WIDTH = 640\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "mean_std_transforms = A.Compose([\n",
    "    A.Resize(width=IMAGE_WIDTH, height=IMAGE_HEIGHT, p=1.0),\n",
    "    A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "mean_std_dataset = MeanStdDataset(\n",
    "    image_paths,\n",
    "    transform=mean_std_transforms\n",
    ")\n",
    "\n",
    "mean_std_dataloader = DataLoader(mean_std_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "mean, std = get_mean_std(mean_std_dataloader)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980cd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(\"data\", \"mean_std_bdd100k.txt\")\n",
    "\n",
    "# write to file\n",
    "with open(save_path, mode=\"w\") as f:\n",
    "    f.write(f\"mean {[round(item.item(), 4) for item in mean]}\\n\")\n",
    "    f.write(f\"std {[round(item.item(), 4) for item in std]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a842a6d1",
   "metadata": {},
   "source": [
    "## 5. Save Labels in Training format\n",
    "\n",
    "### Lable format: label_name x1 y1 x2 y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438c49cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462513c3f98b476d92cc64fb726e8a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc10652d8db41c5b2d00b7e7459b09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_save_dir = os.path.join(\"data\", \"bdd100k_labels_txt\", \"bdd100k\", \"labels\", \"train\")\n",
    "val_save_dir = os.path.join(\"data\", \"bdd100k_labels_txt\", \"bdd100k\", \"labels\", \"val\")\n",
    "\n",
    "attributes = [\"all\", \"occluded\", \"truncated\", \"small\", \"medium\", \"large\", \"uncertain\"]\n",
    "save_labels_txt(train_label_df, attributes, train_files, train_save_dir)\n",
    "save_labels_txt(val_label_df, attributes, val_files, val_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5aa17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
